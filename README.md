# VideoQuery - Multimodal RAG Application

A Multimodal RAG (Retrieval Augmented Generation) application that allows users to upload videos, search visual and audio content, and answer questions about the video.

## Features

- ğŸ¬ **Video Processing**: Extract audio, frames, and generate embeddings
- ğŸ¤ **Audio Transcription**: Transcribe audio using OpenAI Whisper
- ğŸ–¼ï¸ **Visual Search**: Search video frames using CLIP embeddings
- ğŸ’¬ **Natural Language Queries**: Ask questions about video content
- ğŸ¤– **AI-Powered Answers**: Generate answers using Llama 3 (via Groq or Ollama)
- â±ï¸ **Timestamp Citations**: View specific frames at mentioned timestamps

## Tech Stack

- **Backend**: Python, FastAPI
- **AI Processing**: OpenAI Whisper (Audio), OpenAI CLIP (Vision), Llama 3 (Reasoning)
- **Database**: ChromaDB (Local persistence)
- **Frontend**: Streamlit

## Setup

1. **Install dependencies**:
   ```bash
   ./setup.sh
   # Or manually:
   python3 -m venv venv
   source venv/bin/activate
   pip install -r requirements.txt
   ```

2. **Activate virtual environment**:
   ```bash
   source venv/bin/activate
   ```

## Running the Application

### Start the Backend API

Option 1: Run from project root (recommended)
```bash
# From the VideoQuery project root directory
python -m uvicorn backend.api:app --reload --host 0.0.0.0 --port 8000
```

Option 2: Run from backend directory
```bash
cd backend
python api.py
```

The API will run on `http://localhost:8000`

### Start the Frontend

In a new terminal:

```bash
cd frontend
streamlit run app.py
```

The Streamlit app will open in your browser at `http://localhost:8501`

## Usage

1. **Upload a video**: Use the sidebar to upload an MP4 video file
2. **Process the video**: Click "Process Video" to extract frames, transcribe audio, and generate embeddings
3. **Ask questions**: Type questions about the video content in the chat interface
4. **View results**: See AI-generated answers with relevant frames displayed automatically

## Project Structure

```
VideoQuery/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api.py          # FastAPI backend endpoints
â”‚   â”œâ”€â”€ ingest.py       # Video processing pipeline
â”‚   â”œâ”€â”€ database.py     # ChromaDB management
â”‚   â””â”€â”€ rag.py          # RAG query system
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ app.py          # Streamlit UI
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ chromadb/       # ChromaDB persistent storage
â”‚   â”œâ”€â”€ uploads/        # Uploaded video files
â”‚   â””â”€â”€ processed/      # Processed video data
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.sh
â””â”€â”€ README.md
```

## Next Steps

- Implement actual Llama 3 API integration (Groq or Ollama) in `backend/rag.py`
- Add video playback controls
- Support for multiple videos
- Export query results

